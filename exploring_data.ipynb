{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Mapping Summit County, Colorado Ski Areas\n",
      "\n",
      "## Final Project for Udacity\n",
      "## \"Data Wrangling with MongoDB\" course\n",
      "\n",
      "### By: Tyler Byers\n",
      "### January 2015\n",
      "### tybyers@gmail.com\n",
      "\n",
      "======================\n",
      "\n",
      "This is my notebook containing the data parsing/cleaning/writing to JSON steps for the MongoDB final project.   The final project writeup will be in a different notebook.  I chose to explore the Open Street Map of Ski Areas in Summit Country, Colorado -- slightly stepping over county lines to grab Vail Resort (in Eagle County).  The map area can be found at: http://www.openstreetmap.org/#map=11/39.5657/-106.2282.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Check Types of Tags"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Iterative Parsing\n",
      "\n",
      "import xml.etree.ElementTree as ET\n",
      "import pprint\n",
      "\n",
      "def count_tags(filename):\n",
      "    tags = {}\n",
      "    bounds = {}\n",
      "    for event, elem in ET.iterparse(filename):\n",
      "        if elem.tag == \"bounds\":\n",
      "            for latlong in elem.attrib:\n",
      "                bounds[latlong] = elem.attrib[latlong]\n",
      "        if elem.tag in tags.keys():\n",
      "            tags[elem.tag] += 1\n",
      "        else:\n",
      "            tags[elem.tag] = 1\n",
      "    return tags, bounds\n",
      "\n",
      "with open('map_summitco.xml', 'r') as mapfile:\n",
      "    tags, bounds = count_tags(mapfile)\n",
      "    print \"Found tags:\"\n",
      "    pprint.pprint(tags)\n",
      "    print \"\\nMap Area Boundaries:\"\n",
      "    pprint.pprint(bounds)\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found tags:\n",
        "{'bounds': 1,\n",
        " 'member': 6985,\n",
        " 'meta': 1,\n",
        " 'nd': 483072,\n",
        " 'node': 446861,\n",
        " 'note': 1,\n",
        " 'osm': 1,\n",
        " 'relation': 109,\n",
        " 'remark': 1,\n",
        " 'tag': 147934,\n",
        " 'way': 29232}\n",
        "\n",
        "Map Area Boundaries:\n",
        "{'maxlat': '39.7088',\n",
        " 'maxlon': '-105.827',\n",
        " 'minlat': '39.4224',\n",
        " 'minlon': '-106.457'}\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Check k-values\n",
      "\n",
      "Going to check to see if we have any k values with problematic characters.\n",
      "\n",
      "Also, for the k values separated with a colon, wish to see what the k:ktype pairs are."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xml.etree.ElementTree as ET\n",
      "import pprint\n",
      "import re\n",
      "\n",
      "lower = re.compile(r'^([a-z]|_)*$')\n",
      "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
      "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
      "lower_colon_vals = {}\n",
      "\n",
      "def key_type(element, keys):\n",
      "    if element.tag == \"tag\":\n",
      "        kval = element.attrib['k']\n",
      "        if re.search(lower, kval):\n",
      "            keys['lower'] += 1\n",
      "        elif re.search(lower_colon, kval):\n",
      "            keys['lower_colon'] += 1\n",
      "            colvals = kval.split(':')\n",
      "            if colvals[0] not in lower_colon_vals.keys():\n",
      "                lower_colon_vals[colvals[0]] = set()\n",
      "            lower_colon_vals[colvals[0]].add(colvals[1])\n",
      "        elif re.search(problemchars, kval):\n",
      "            keys['problemchars'] += 1\n",
      "        else:\n",
      "            keys['other'] += 1\n",
      "        \n",
      "    return keys\n",
      "\n",
      "\n",
      "def process_map(filename):\n",
      "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
      "    for _, element in ET.iterparse(filename):\n",
      "        keys = key_type(element, keys)\n",
      "\n",
      "    return keys\n",
      "\n",
      "with open('map_summitco.xml', 'r') as mapfile:\n",
      "    keys = process_map(mapfile)\n",
      "    print \"Types of k-values and their counts:\"\n",
      "    pprint.pprint(keys)\n",
      "    pinrt \"Types of colon-separated k-values:\"\n",
      "    pprint.pprint(lower_colon_vals)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'lower': 75413, 'lower_colon': 20285, 'other': 52236, 'problemchars': 0}\n",
        "{'addr': set(['city',\n",
        "              'country',\n",
        "              'full',\n",
        "              'housename',\n",
        "              'housenumber',\n",
        "              'interpolation',\n",
        "              'postcode',\n",
        "              'state',\n",
        "              'street']),\n",
        " 'aerialway': set(['chari_lift', 'duration', 'occupancy']),\n",
        " 'building': set(['levels', 'min_level']),\n",
        " 'census': set(['population']),\n",
        " 'contact': set(['email', 'fax', 'phone', 'website']),\n",
        " 'disused': set(['building']),\n",
        " 'ele': set(['feet', 'ft']),\n",
        " 'generator': set(['source']),\n",
        " 'gnis': set(['county_id',\n",
        "              'county_name',\n",
        "              'created',\n",
        "              'feature_id',\n",
        "              'feature_type',\n",
        "              'id',\n",
        "              'import_uuid',\n",
        "              'state_id']),\n",
        " 'hgv': set(['national_network']),\n",
        " 'internet_access': set(['fee']),\n",
        " 'is_in': set(['country', 'country_code', 'state', 'state_code']),\n",
        " 'lanes': set(['backward', 'forward']),\n",
        " 'name': set(['he']),\n",
        " 'nist': set(['fips_code', 'state_fips']),\n",
        " 'payment': set(['bitcoin']),\n",
        " 'piste': set(['difficulty',\n",
        "               'grooming',\n",
        "               'lift',\n",
        "               'oneway',\n",
        "               'reviewed',\n",
        "               'type']),\n",
        " 'roof': set(['shape']),\n",
        " 'seamark': set(['type']),\n",
        " 'source': set(['ele', 'name']),\n",
        " 'tiger': set(['cfcc',\n",
        "               'county',\n",
        "               'name_base',\n",
        "               'name_direction_prefix',\n",
        "               'name_direction_suffix',\n",
        "               'name_type',\n",
        "               'reviewed',\n",
        "               'separated',\n",
        "               'source',\n",
        "               'tlid',\n",
        "               'upload_uuid',\n",
        "               'zip_left',\n",
        "               'zip_right']),\n",
        " 'toilets': set(['disposal', 'position']),\n",
        " 'tower': set(['type']),\n",
        " 'turn': set(['lanes'])}\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Observations:\n",
      "\n",
      "* The k-values shouldn't cause us problems, as far as \"problem characters\" are concerned.\n",
      "* For aerialways, \"chari_lift\" is clearly a typo, while aerialway:duration and aerialway:occupancy are valid tags.  Might need to make an aerialway:type tag for the database.\n",
      "* The ele:ft and ele:feet tags occur pretty infrequently -- only twice in these data (counted found using grep), once each.  Generally, ele, or elevation, is a value in meters.  For both of these features that list elevation in feet, there is also an elevation in meters listed, so we will ignore the values in feet.\n",
      "* The \"name:he\" tag is weird.  I did a grep on it, and saw some non-English characters (only occurred once).  Can ignore this.\n",
      "* The tiger tags were a surprise to me -- turns out those were from the TIGER import of the USA (http://wiki.openstreetmap.org/wiki/Key:tiger:cfcc?uselang=en-US).  After exploring the map and grep'ing a number of these tags, they seem redundant compared to all the other informaion.  We'll keep these in the data set because they will provide some interesting statistics (how many of our documents have been updated lately vs. in the automated process), but aren't going to clean any of the tags up.\n",
      "* All the \"piste\" settings will need to be in their own sub-document in MongoDB.  \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Find number of unique users"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xml.etree.ElementTree as ET\n",
      "import pprint\n",
      "import re\n",
      "\n",
      "def get_userid(element):\n",
      "    return element.attrib['uid']\n",
      "\n",
      "def get_username(element):\n",
      "    return element.attrib['user']\n",
      "\n",
      "def process_map(filename):\n",
      "    userids = set()\n",
      "    usernames = set()\n",
      "    for _, element in ET.iterparse(filename):\n",
      "        if 'uid' in element.attrib.keys():\n",
      "            userid = get_userid(element)\n",
      "            userids.add(userid)\n",
      "        if 'user' in element.attrib.keys():\n",
      "            username = get_username(element)\n",
      "            usernames.add(username)\n",
      "\n",
      "    return userids, usernames\n",
      "\n",
      "with open('map_summitco.xml', 'r') as mapfile:\n",
      "    userids, usernames = process_map(mapfile)\n",
      "    print \"There are %d unique user IDs\" % len(userids)\n",
      "    print \"There are %d unique usernames\" % len(usernames)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "There are 185 unique user IDs\n",
        "There are 185 unique usernames\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So 185 different folks have contributed to this map --- and we were making sure usernames and IDs were tied together 1:1 -- it looks like they are. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Auditing Street Types"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xml.etree.cElementTree as ET\n",
      "from collections import defaultdict\n",
      "import re\n",
      "import pprint\n",
      "\n",
      "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
      "\n",
      "\n",
      "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
      "            \"Trail\", \"Parkway\", \"Commons\"]\n",
      "\n",
      "\n",
      "def audit_street_type(street_types, street_name, street_types_count):\n",
      "    m = street_type_re.search(street_name)\n",
      "    if m:\n",
      "        street_type = m.group()\n",
      "        if street_type not in street_types_count.keys():\n",
      "            street_types_count[street_type] = 1\n",
      "        else:\n",
      "            street_types_count[street_type] += 1\n",
      "        if street_type not in expected:\n",
      "            street_types[street_type].add(street_name)\n",
      "            \n",
      "    return street_types_count\n",
      "\n",
      "def is_street_name(elem):\n",
      "    return (elem.attrib['k'] == \"addr:street\")\n",
      "\n",
      "def audit(mapfile):\n",
      "    street_types = defaultdict(set)\n",
      "    street_types_count = {}\n",
      "    for event, elem in ET.iterparse(mapfile, events=(\"start\",)):\n",
      "\n",
      "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
      "            for tag in elem.iter(\"tag\"):\n",
      "                if is_street_name(tag):\n",
      "                    street_types_count = audit_street_type(street_types, tag.attrib['v'], street_types_count)\n",
      "\n",
      "    return street_types, street_types_count\n",
      "\n",
      "with open('map_summitco.xml', 'r') as mapfile:\n",
      "    street_types, street_types_count = audit(mapfile)\n",
      "    print \"Possible Street Types Problems:\"\n",
      "    pprint.pprint(street_types)\n",
      "    print \"Count of Street Types:\"\n",
      "    pprint.pprint(street_types_count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Possible Street Types Problems:\n",
        "defaultdict(<type 'set'>, {'9': set(['Highway 9', 'North Highway 9']), 'Circle': set(['Ryan Gulch Circle', 'Legend Lake Circle']), 'center': set(['summit place  shopping  center'])})\n",
        "Count of Street Types:\n",
        "{'9': 3,\n",
        " 'Avenue': 5,\n",
        " 'Circle': 45,\n",
        " 'Court': 16,\n",
        " 'Drive': 44,\n",
        " 'Lane': 4,\n",
        " 'Road': 83,\n",
        " 'Street': 34,\n",
        " 'center': 1}\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Overall that list looks pretty good -- we didn't have as many problems as we even did in the class data set.  That being said, there are a few things of note:\n",
      "\n",
      "* Need to add \"Circle\" to `expected` list\n",
      "* Seems to be far too few streets for this list.  Big area, should we have more addr:street listings?\n",
      " * Did a bit more digging, discovered that many of the \"way\" tags, actually most, do not have an addr:street listing.  Should we fix this?\n",
      "* \"Circle\" seems to be over-represented compared to the other street types\n",
      "* \"Highway 9\" and \"North Highway 9\" turn out to be valid address designators for buildings along Highway 9 outside of Breckenridge.\n",
      "* Noticed as I \"walked\" down Breckenridge Main Street that only a small percentage of businesses are actually mentioned.  All the buildings on there, but very few businesses identified.  So later statistics will not really be accurate.\n",
      "*  The \"summit place  shopping  center\" location turns out to be within the Node for the \"Steaming Bean\" coffee house.  That street address should be changed to just \"Summit Place\".  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Explore Chair Lifts\n",
      "Since this is \"ski country,\" I want to look at the chair lifts, which are designated with the tag `k=\"aerialway\"` in the data set.  What kinds of aerialways do we have in our data set?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xml.etree.ElementTree as ET\n",
      "import pprint\n",
      "\n",
      "def is_aerialway(elem):\n",
      "    return (elem.attrib['k'] == \"aerialway\")\n",
      "\n",
      "def process_map(filename):\n",
      "    aerialways = set()\n",
      "    for event, elem in ET.iterparse(mapfile, events=(\"start\",)):\n",
      "\n",
      "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
      "            for tag in elem.iter(\"tag\"):\n",
      "                if is_aerialway(tag):\n",
      "                    aerialways.add(tag.attrib['v'])\n",
      "    return aerialways\n",
      "\n",
      "\n",
      "with open('map_summitco.xml', 'r') as mapfile:\n",
      "    aerialways = process_map(mapfile)\n",
      "    pprint.pprint(aerialways)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set(['chair_lift',\n",
        "     'drag_lift',\n",
        "     'gondola',\n",
        "     'magic_carpet',\n",
        "     'platter',\n",
        "     'pylon',\n",
        "     'station',\n",
        "     't-bar',\n",
        "     'yes'])\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Of these, I will want to look at chair_lift, drag_lift, gondola, magic_carpet, and t_bar.  What are the names of the various chair lfits. Do these need to be fixed?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xml.etree.ElementTree as ET\n",
      "import pprint\n",
      "from collections import defaultdict\n",
      "\n",
      "def add_aerialway_name(aerialways, lifttype, elem):\n",
      "    for tag in elem.iter(\"tag\"):\n",
      "        if tag.attrib['k'] == \"name\":\n",
      "            aerialways[lifttype].append(tag.attrib['v'])\n",
      "    \n",
      "def is_lift(elem):\n",
      "    accepted_lifts = [\"chair_lift\", \"drag_lift\", \"gondola\", \"magic_carpet\", \"t-bar\"]\n",
      "    return (elem.attrib['k'] == \"aerialway\" and elem.attrib['v'] in accepted_lifts)\n",
      "\n",
      "def process_map(filename):\n",
      "    aerialways = defaultdict(list)\n",
      "    for event, elem in ET.iterparse(mapfile, events=(\"start\",)):\n",
      "\n",
      "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
      "            for tag in elem.iter(\"tag\"):\n",
      "                if is_lift(tag):\n",
      "                    add_aerialway_name(aerialways, tag.attrib['v'], elem)\n",
      "    return aerialways\n",
      "\n",
      "\n",
      "with open('map_summitco.xml', 'r') as mapfile:\n",
      "    aerialways = process_map(mapfile)\n",
      "    pprint.pprint(aerialways)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "defaultdict(<type 'list'>, {'t-bar': ['T-Bar'], 'gondola': ['Eagle Bahn Gondola (19)', 'Breck Connect Gondola', 'River Run Gondola', 'Outpost Gondola'], 'magic_carpet': ['Slingshot', 'Easy Rider', 'Stinger'], 'drag_lift': ['Storm King', 'Gem', 'Mongolia (22)', 'Wapiti (24)'], 'chair_lift': ['Poma', 'Lift 3', 'Lift 2', 'Lift 1', 'Lift 7', 'Lift 6', 'Lift 4', 'Gondola One (1)', 'Riva Bahn Express Lift (6)', 'Northwoods Express Lift (11)', 'Highline Express Lift (10)', 'Wildwood Express Lift (3)', 'High Noon Express Lift (5)', 'Game Creek Express Lift (7)', 'Argentine', 'Discovery', 'A-51', 'Peru Express', 'Montezuma Express', 'Lenawee Mountain Lift', '5-Chair', 'Molly Hogan Lift', 'Colorado SuperChair', 'Independence SuperChair', 'Peak 8 SuperConnect', 'Mercury SuperChair', 'Falcon SuperChair', 'C-Chair', 'Beaver Run SuperChair', 'Imperial Express SuperChair', '6-Chair', 'QuickSilver SuperChair', 'E-Chair', 'Snowflake', \"Rip's Ride\", 'Pallavicini Lift', 'Black Mountain Express', 'Lift 9', 'Lift 8', 'Timberline Express', 'American Flyer', 'Excelerator', 'Resolution', 'American Eagle', 'Union Creek', 'Alpine', 'Sierra', 'Kokomo', 'Rendezvous', 'Mountain Chief', 'Lumberjack', 'Blackjack', 'Super Bee', 'Pitchfork', 'Pride Express Lift (26)', 'Tea Cup Express Lift (36)', 'Orient Express Lift (21)', 'Skyline Express Lift (37)', \"Pete's Express Lift (39)\", 'Sun Up Lift (17)', 'Mountain Top Express Lift (4)', 'Avanti Express Lift (2)', 'Sourdough Express Lift (14)', \"Earl's Express Lift (38)\", 'Summit Express', 'Outback Express', 'Santiago Express', 'Ruby Express', 'Wayback', 'Zuma Lift', 'Born Free Express Lift (8)', 'Ranger', 'A-Chair', 'Rocky Mountain SuperChair', 'Cascade Village Lift', 'Gopher Hill Lift', 'Norway Lift', 'Zendo Chair', 'Kensho SuperChair']})\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I see no problems with these chair lift names thatneed to be fixed.  The numbers in the sames are valid (Sourdough Express Lift is a.k.a \"Chair 14\")."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Elevations of Peaks\n",
      "\n",
      "I noticed when exploring the map near Breckenridge that not all the peaks had elevations listed.  Which ones are they?  Can we fix them?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xml.etree.ElementTree as ET\n",
      "import pprint\n",
      "from collections import defaultdict\n",
      "\n",
      "peaks = {'elev_known': [], 'elev_unknown': []}\n",
      "\n",
      "def add_to_elev_known(elem):\n",
      "    for tag in elem.iter(\"tag\"):\n",
      "        if tag.attrib['k'] == 'name':\n",
      "            peaks['elev_known'].append(tag.attrib['v'])\n",
      "            return\n",
      "\n",
      "def add_to_elev_unknown(elem):\n",
      "    for tag in elem.iter(\"tag\"):\n",
      "        if tag.attrib['k'] == 'name':\n",
      "            peaks['elev_unknown'].append(tag.attrib['v'])\n",
      "            return\n",
      "    \n",
      "def check_peak_elev(elem):\n",
      "    for tag in elem.iter(\"tag\"):\n",
      "        if tag.attrib['k'] == 'ele':\n",
      "            add_to_elev_known(elem)\n",
      "            return\n",
      "    # if no ele tag found, add_to_elev_unknown\n",
      "    add_to_elev_unknown(elem)\n",
      "            \n",
      "def is_peak(tag):\n",
      "    return (tag.attrib['k'] == \"natural\" and tag.attrib['v'] == 'peak')\n",
      "\n",
      "def process_map(filename):\n",
      "    for event, elem in ET.iterparse(mapfile, events=(\"start\",)):\n",
      "        if elem.tag == \"node\":\n",
      "            for tag in elem.iter(\"tag\"):\n",
      "                if is_peak(tag):\n",
      "                    check_peak_elev(elem)\n",
      "    return aerialways\n",
      "\n",
      "\n",
      "with open('map_summitco.xml', 'r') as mapfile:\n",
      "    aerialways = process_map(mapfile)\n",
      "    print peaks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'elev_known': ['Mount Powell', 'Bald Mountain', 'Red Peak', 'Keller Mountain', 'Ptarmigan Peak', 'Lionshead', 'Shrine Mountain', 'Battle Mountain', 'Ptarmigan Point', 'Uneva Peak', 'Buffalo Mountain', 'Tenmile Peak', 'Tenmile Range Peak 3', 'Tenmile Range Peak 4', 'Tenmile Range Peak 5', 'Swan Mountain', 'Ophir Mountain', 'Royal Mountain', 'Tenmile Range Peak 1', 'Hornsilver Mountain', 'Resolution Mountain', 'Ptarmigan Hill', 'Sugarloaf Peak', 'Mayflower Hill', 'Elk Mountain', 'Pearl Peak', 'Corbett Peak', 'North Sheep Mountain', 'Jacque Peak', 'Tucker Mountain', 'Tenmile Range Peak 6', 'Tenmile Range Peak 7', 'Tenmile Range Peak 8', 'Shock Hill', 'Gibson Hill', 'Prospect Hill', 'Barney Ford Hill', 'Little Mountain', 'Peak 9', 'Tenmile Range Peak 10', 'Crystal Peak', 'Mount Helen', 'Pacific Peak', 'Mount Argentine', 'Mount Trelease', 'Coon Hill', 'Grizzly Peak', 'Baker Mountain', 'Mount Sniktau', 'Wise Mountain', 'Independence Mountain', 'Bear Mountain', 'Porcupine Peak', 'Handcart Peak', 'Radical Hill', 'Teller Mountain', 'Sullivan Mountain', 'Santa Fe Peak', 'Tiptop Peak', 'Morgan Peak', 'Cooper Mountain', 'Mineral Hill', 'Humbug Hill', 'Glacier Peak', 'Mount Guyot', 'Farncomb Hill', 'Bald Mountain', 'Whale Peak', 'Lake Hill', 'Vail Mountain', 'Father Dyer Peak', 'Tenderfoot Mountain', 'Iron Mountain', 'Wichita Mountain', 'Chief Mountain', 'Lenawee Mountain', 'Brewery Hill', 'Glacier Mountain', 'Sheep Mountain', 'Golden Bear Peak'], 'elev_unknown': ['Peak 8', 'Peak 7', 'Peak 10']}\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are only three peaks with unlisted elevations -- Peak 8, Peak 7, and Peak 10.  These peaks are actually captured as Tenmile Range Peaks 8, 7, and 10, so they are duplicates.  We will eventually remove them from our database."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Pistes (mostly a.k.a ski runs)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}